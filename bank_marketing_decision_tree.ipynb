{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "67e80e15",
   "metadata": {},
   "source": [
    "\n",
    "# Bank Marketing â€” Data Cleaning, EDA & Decision Tree Classifier\n",
    "\n",
    "This notebook performs a full data cleaning, exploratory data analysis (EDA), and builds a Decision Tree classifier\n",
    "to predict whether a customer will subscribe to a term deposit (`y` = yes/no) using the UCI Bank Marketing dataset.\n",
    "\n",
    "**How to use**\n",
    "1. Place the dataset CSV (`bank-additional-full.csv` or `bank-additional/bank-additional-full.csv`) in the same folder as this notebook, **or**\n",
    "2. Let the notebook download the dataset from the UCI repository automatically (requires internet in the environment).\n",
    "3. Run cells step-by-step in Jupyter, VS Code (Jupyter), or Google Colab.\n",
    "\n",
    "**Outputs**\n",
    "- Cleaned dataset saved as `bank_cleaned.csv`\n",
    "- Trained Decision Tree model and evaluation metrics\n",
    "- Plots for EDA and model interpretation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "457b7cbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# === Setup ===\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeClassifier, plot_tree\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix, roc_auc_score, roc_curve\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# Display settings\n",
    "pd.set_option('display.max_columns', 200)\n",
    "sns.set(style='whitegrid')\n",
    "%matplotlib inline\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40e68a03",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# === Load dataset (try local, else download from UCI) ===\n",
    "local_paths = [\n",
    "    \"bank-additional-full.csv\",\n",
    "    \"bank-additional/bank-additional-full.csv\",\n",
    "    \"bank.csv\",\n",
    "    \"bank-additional.csv\"\n",
    "]\n",
    "\n",
    "df = None\n",
    "for p in local_paths:\n",
    "    if os.path.exists(p):\n",
    "        df = pd.read_csv(p, sep=';')\n",
    "        print(f\"Loaded local file: {p}\")\n",
    "        break\n",
    "\n",
    "if df is None:\n",
    "    print(\"Local file not found. Attempting to download from UCI repository...\")\n",
    "    url = \"https://archive.ics.uci.edu/ml/machine-learning-databases/00222/bank-additional.zip\"\n",
    "    try:\n",
    "        import requests, zipfile, io\n",
    "        r = requests.get(url)\n",
    "        z = zipfile.ZipFile(io.BytesIO(r.content))\n",
    "        # The zip contains directory 'bank-additional' with 'bank-additional-full.csv'\n",
    "        fname = None\n",
    "        for name in z.namelist():\n",
    "            if name.endswith(\"bank-additional-full.csv\"):\n",
    "                fname = name\n",
    "                break\n",
    "        if fname is None:\n",
    "            raise RuntimeError(\"Dataset file not found inside zip archive.\")\n",
    "        z.extract(fname, \".\")\n",
    "        extracted_path = fname  # e.g., 'bank-additional/bank-additional-full.csv'\n",
    "        df = pd.read_csv(extracted_path, sep=';')\n",
    "        print(\"Downloaded and extracted:\", extracted_path)\n",
    "    except Exception as e:\n",
    "        raise RuntimeError(\"Could not load dataset locally and failed to download. Please upload the CSV file to the environment.\") from e\n",
    "\n",
    "print('\\nDataset shape:', df.shape)\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "daf80e1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# === Data Cleaning ===\n",
    "# Overview\n",
    "print(\"\\nColumns:\\n\", df.columns.tolist())\n",
    "print(\"\\nInfo:\")\n",
    "display(df.info())\n",
    "\n",
    "# The UCI bank dataset uses 'unknown' to indicate missing values for categorical features.\n",
    "df = df.replace('unknown', np.nan)\n",
    "\n",
    "print(\"\\nMissing values per column:\")\n",
    "print(df.isnull().sum())\n",
    "\n",
    "# Strategy:\n",
    "# - For numeric columns: fill NaN with median\n",
    "# - For categorical columns: fill NaN with mode\n",
    "numeric_cols = df.select_dtypes(include=[np.number]).columns.tolist()\n",
    "categorical_cols = df.select_dtypes(include=['object']).columns.tolist()\n",
    "\n",
    "for col in numeric_cols:\n",
    "    if df[col].isnull().sum() > 0:\n",
    "        med = df[col].median()\n",
    "        df[col].fillna(med, inplace=True)\n",
    "        print(f\"Filled numeric {col} NaNs with median: {med}\")\n",
    "\n",
    "for col in categorical_cols:\n",
    "    if df[col].isnull().sum() > 0:\n",
    "        mode = df[col].mode()[0]\n",
    "        df[col].fillna(mode, inplace=True)\n",
    "        print(f\"Filled categorical {col} NaNs with mode: {mode}\")\n",
    "\n",
    "# Convert month and day_of_week to categorical ordered types if desired\n",
    "if 'month' in df.columns:\n",
    "    month_order = ['jan','feb','mar','apr','may','jun','jul','aug','sep','oct','nov','dec']\n",
    "    df['month'] = pd.Categorical(df['month'], categories=month_order, ordered=True)\n",
    "\n",
    "# Save a cleaned copy (before encoding)\n",
    "cleaned_path = \"bank_cleaned.csv\"\n",
    "df.to_csv(cleaned_path, index=False)\n",
    "print(\"\\nSaved cleaned dataset to:\", cleaned_path)\n",
    "\n",
    "print(\"\\nAfter cleaning, missing values:\")\n",
    "print(df.isnull().sum())\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc6533cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# === Exploratory Data Analysis (EDA) ===\n",
    "# Target distribution\n",
    "plt.figure(figsize=(6,4))\n",
    "sns.countplot(data=df, x='y')\n",
    "plt.title('Target Distribution (y)')\n",
    "plt.xlabel('Subscribed (yes/no)')\n",
    "plt.show()\n",
    "\n",
    "# Convert target to 0/1 for analysis\n",
    "df['y_binary'] = df['y'].map({'no':0, 'yes':1})\n",
    "\n",
    "# Categorical feature overview: show top categories for a few features\n",
    "cat_features = ['job','marital','education','default','housing','loan','contact','poutcome']\n",
    "for feat in cat_features:\n",
    "    if feat in df.columns:\n",
    "        plt.figure(figsize=(8,3))\n",
    "        order = df[feat].value_counts().index\n",
    "        sns.countplot(data=df, x=feat, order=order)\n",
    "        plt.title(f'Distribution of {feat}')\n",
    "        plt.xticks(rotation=45)\n",
    "        plt.show()\n",
    "\n",
    "# Average subscription rate by job\n",
    "if 'job' in df.columns:\n",
    "    job_rate = df.groupby('job')['y_binary'].mean().sort_values(ascending=False)\n",
    "    display(job_rate.head(10))\n",
    "\n",
    "    plt.figure(figsize=(10,4))\n",
    "    job_rate.plot(kind='bar')\n",
    "    plt.title('Subscription rate by Job')\n",
    "    plt.ylabel('Proportion subscribed')\n",
    "    plt.show()\n",
    "\n",
    "# Numeric feature summaries and distributions\n",
    "num_feats = ['age','duration','campaign','pdays','previous','emp.var.rate','cons.price.idx','cons.conf.idx','euribor3m','nr.employed']\n",
    "existing_num_feats = [c for c in num_feats if c in df.columns]\n",
    "for c in existing_num_feats:\n",
    "    plt.figure(figsize=(8,3))\n",
    "    sns.histplot(df[c], bins=40, kde=True)\n",
    "    plt.title(f'Distribution of {c}')\n",
    "    plt.show()\n",
    "\n",
    "# Relationship between numeric features and target (boxplots)\n",
    "for c in ['age','duration','campaign','pdays']:\n",
    "    if c in df.columns:\n",
    "        plt.figure(figsize=(8,4))\n",
    "        sns.boxplot(x='y', y=c, data=df)\n",
    "        plt.title(f'{c} by Subscription')\n",
    "        plt.show()\n",
    "\n",
    "# Correlation heatmap for numeric features (use y_binary too)\n",
    "plt.figure(figsize=(10,8))\n",
    "corr = df.select_dtypes(include=[np.number]).corr()\n",
    "sns.heatmap(corr, annot=True, fmt='.2f', cmap='coolwarm', center=0)\n",
    "plt.title('Correlation Matrix (numeric)')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a321135d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# === Modeling: Decision Tree Classifier ===\n",
    "# Prepare data: encode categorical variables with get_dummies (one-hot), label encode target\n",
    "X = df.drop(columns=['y','y_binary']) if 'y' in df.columns else df.drop(columns=['y_binary'])\n",
    "y = df['y_binary']\n",
    "\n",
    "# One-hot encode categorical columns\n",
    "X_encoded = pd.get_dummies(X, drop_first=True)\n",
    "\n",
    "print(\"Shape after encoding:\", X_encoded.shape)\n",
    "\n",
    "# Train-test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_encoded, y, test_size=0.2, random_state=42, stratify=y)\n",
    "\n",
    "# Train Decision Tree\n",
    "clf = DecisionTreeClassifier(max_depth=6, random_state=42)\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "# Predictions & evaluation\n",
    "y_pred = clf.predict(X_test)\n",
    "y_proba = clf.predict_proba(X_test)[:,1]\n",
    "\n",
    "acc = accuracy_score(y_test, y_pred)\n",
    "print(f\"Accuracy: {acc:.4f}\")\n",
    "print(\"\\nClassification Report:\\n\", classification_report(y_test, y_pred))\n",
    "\n",
    "# Confusion matrix\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "plt.figure(figsize=(5,4))\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues')\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('Actual')\n",
    "plt.title('Confusion Matrix')\n",
    "plt.show()\n",
    "\n",
    "# ROC AUC\n",
    "try:\n",
    "    roc_auc = roc_auc_score(y_test, y_proba)\n",
    "    print(f\"ROC AUC: {roc_auc:.4f}\")\n",
    "    fpr, tpr, _ = roc_curve(y_test, y_proba)\n",
    "    plt.figure(figsize=(6,4))\n",
    "    plt.plot(fpr, tpr, label=f'AUC = {roc_auc:.3f}')\n",
    "    plt.plot([0,1],[0,1], linestyle='--')\n",
    "    plt.xlabel('False Positive Rate')\n",
    "    plt.ylabel('True Positive Rate')\n",
    "    plt.title('ROC Curve')\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "except Exception as e:\n",
    "    print('ROC AUC could not be computed:', e)\n",
    "\n",
    "# Feature importances (top 20)\n",
    "feat_imp = pd.Series(clf.feature_importances_, index=X_encoded.columns).sort_values(ascending=False).head(20)\n",
    "plt.figure(figsize=(10,5))\n",
    "sns.barplot(x=feat_imp.values, y=feat_imp.index)\n",
    "plt.title('Top 20 Feature Importances (Decision Tree)')\n",
    "plt.show()\n",
    "\n",
    "# Visualize the tree (smaller depth)\n",
    "plt.figure(figsize=(20,10))\n",
    "plot_tree(clf, feature_names=X_encoded.columns, class_names=['no','yes'], filled=True, rounded=True, max_depth=3)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ff86168",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# === Save final cleaned & encoded dataset if needed ===\n",
    "# Save the cleaned (pre-encoding) dataset already saved earlier as bank_cleaned.csv\n",
    "print(\"Cleaned dataset is saved as 'bank_cleaned.csv' in the current directory.\")\n"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
